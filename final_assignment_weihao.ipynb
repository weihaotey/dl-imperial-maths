{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    '''A function to read idx file format into numpy array'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
    "    \n",
    "train_set = read_idx('train-images-idx3-ubyte (1)')\n",
    "train_set = np.expand_dims(train_set, axis=3)\n",
    "print(train_set.shape)\n",
    "train_label = read_idx('train-labels-idx1-ubyte (1)')\n",
    "train_label = np.expand_dims(train_label, axis=1)\n",
    "print(train_label.shape)\n",
    "\n",
    "test_set = read_idx('t10k-images-idx3-ubyte (1)')\n",
    "test_set = np.expand_dims(test_set, axis=3)\n",
    "print(test_set.shape)\n",
    "test_label = read_idx('t10k-labels-idx1-ubyte (1)')\n",
    "test_label = np.expand_dims(test_label, axis=1)\n",
    "print(test_label.shape)\n",
    "n_train = train_set.shape[0]\n",
    "n_test = test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
    "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.squeeze(labels)\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0] * 10\n",
    "        if num == 10:\n",
    "            one_hot[0] = 1.0\n",
    "        else:\n",
    "            one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    labels = np.array(one_hot_labels).astype(np.float32)\n",
    "    return labels\n",
    "\n",
    "train_label_one_hot = one_hot(train_label)\n",
    "test_label_one_hot = one_hot(test_label)\n",
    "\n",
    "print(train_label_one_hot.shape)\n",
    "print(test_label_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_CNN:\n",
    "    def __init__(self, wd_factor, learning_rate): #initialize all the variable to be used in the other functions\n",
    "        self.wd_factor = wd_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='input') #to make a 28 times 28 minipatch swipe\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
    "        \n",
    "        # For batch norm and dropout\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        print(self.input)\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        weights = []  # for weight decay\n",
    "        \n",
    "        with tf.variable_scope('layers'):\n",
    "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
    "            \n",
    "            # Downsample\n",
    "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
    "            print(h)\n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.flatten(h)\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                activation=tf.nn.relu, name='dense1')\n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
    "            print(h)\n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                          activation=tf.identity, name='dense2')\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
    "                                                                                  labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay()\n",
    "            \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "    def weight_decay(self):\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer:]\n",
    "            self.train_pointer = 0\n",
    "        return samples_minibatch, labels_minibatch\n",
    "\n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
    "        print('Start Training')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                \n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "                    \n",
    "            saver.save(sess, './model')\n",
    "        return losses\n",
    "                    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer:]\n",
    "            self.test_pointer = 0\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "            \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        self.test_pointer = 0\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "            saver.restore(sess, './model')\n",
    "            while not end_of_epoch:\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
    "        print(\"Average test loss: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"layers/pool1/MaxPool:0\", shape=(?, 3, 3, 64), dtype=float32)\n",
      "Tensor(\"layers/flatten/Reshape:0\", shape=(?, 576), dtype=float32)\n",
      "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dropout1/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/conv1/kernel:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Minibatch loss at step 0: 3.0114216804504395\n",
      "Minibatch loss at step 50: 0.868087887763977\n",
      "Minibatch loss at step 100: 0.5275111198425293\n",
      "Minibatch loss at step 150: 0.6371699571609497\n",
      "Minibatch loss at step 200: 0.5396888852119446\n",
      "Minibatch loss at step 250: 0.42099529504776\n",
      "Minibatch loss at step 300: 0.42500099539756775\n",
      "Minibatch loss at step 350: 0.6470173597335815\n",
      "Minibatch loss at step 400: 0.4464397132396698\n",
      "Minibatch loss at step 450: 0.38633400201797485\n",
      "Minibatch loss at step 500: 0.5718162655830383\n",
      "Minibatch loss at step 550: 0.45218992233276367\n",
      "Minibatch loss at step 600: 0.4536758363246918\n",
      "Minibatch loss at step 650: 0.47878047823905945\n",
      "Minibatch loss at step 700: 0.432206928730011\n",
      "Minibatch loss at step 750: 0.5118241310119629\n",
      "Minibatch loss at step 800: 0.3365168571472168\n",
      "Minibatch loss at step 850: 0.22940361499786377\n",
      "Minibatch loss at step 900: 0.4087319076061249\n",
      "Minibatch loss at step 950: 0.30383309721946716\n",
      "Minibatch loss at step 1000: 0.4350360333919525\n",
      "Minibatch loss at step 1050: 0.3667442202568054\n",
      "Minibatch loss at step 1100: 0.37924903631210327\n",
      "Minibatch loss at step 1150: 0.3619573414325714\n",
      "Minibatch loss at step 1200: 0.34695327281951904\n",
      "Minibatch loss at step 1250: 0.5545283555984497\n",
      "Minibatch loss at step 1300: 0.3150714933872223\n",
      "Minibatch loss at step 1350: 0.29879388213157654\n",
      "Minibatch loss at step 1400: 0.3535331189632416\n",
      "Minibatch loss at step 1450: 0.2924617826938629\n",
      "Minibatch loss at step 1500: 0.227833554148674\n",
      "Minibatch loss at step 1550: 0.26046139001846313\n",
      "Minibatch loss at step 1600: 0.36455845832824707\n",
      "Minibatch loss at step 1650: 0.4339379072189331\n",
      "Minibatch loss at step 1700: 0.27252763509750366\n",
      "Minibatch loss at step 1750: 0.2885928153991699\n",
      "Minibatch loss at step 1800: 0.2576349973678589\n",
      "Minibatch loss at step 1850: 0.2170233279466629\n",
      "Minibatch loss at step 1900: 0.3184424638748169\n",
      "Minibatch loss at step 1950: 0.3965038061141968\n",
      "Minibatch loss at step 2000: 0.2713685929775238\n",
      "Minibatch loss at step 2050: 0.2235020101070404\n",
      "Minibatch loss at step 2100: 0.3031219244003296\n",
      "Minibatch loss at step 2150: 0.2347041666507721\n",
      "Minibatch loss at step 2200: 0.19860951602458954\n",
      "Minibatch loss at step 2250: 0.2138628512620926\n",
      "Minibatch loss at step 2300: 0.24268867075443268\n",
      "Minibatch loss at step 2350: 0.23643289506435394\n",
      "Minibatch loss at step 2400: 0.23225408792495728\n",
      "Minibatch loss at step 2450: 0.2825288772583008\n",
      "Minibatch loss at step 2500: 0.3497419059276581\n",
      "Minibatch loss at step 2550: 0.24844634532928467\n",
      "Minibatch loss at step 2600: 0.15697354078292847\n",
      "Minibatch loss at step 2650: 0.2444307506084442\n",
      "Minibatch loss at step 2700: 0.19298481941223145\n",
      "Minibatch loss at step 2750: 0.28609412908554077\n",
      "Minibatch loss at step 2800: 0.28780245780944824\n",
      "Minibatch loss at step 2850: 0.19469252228736877\n",
      "Minibatch loss at step 2900: 0.19922994077205658\n",
      "Minibatch loss at step 2950: 0.2714630961418152\n",
      "Minibatch loss at step 3000: 0.2081737071275711\n",
      "Minibatch loss at step 3050: 0.21310757100582123\n",
      "Minibatch loss at step 3100: 0.30501633882522583\n",
      "Minibatch loss at step 3150: 0.141911581158638\n",
      "Minibatch loss at step 3200: 0.31289172172546387\n",
      "Minibatch loss at step 3250: 0.2319125533103943\n",
      "Minibatch loss at step 3300: 0.32822316884994507\n",
      "Minibatch loss at step 3350: 0.2540707588195801\n",
      "Minibatch loss at step 3400: 0.3300379514694214\n",
      "Minibatch loss at step 3450: 0.1754712164402008\n",
      "Minibatch loss at step 3500: 0.12642362713813782\n",
      "Minibatch loss at step 3550: 0.16695353388786316\n",
      "Minibatch loss at step 3600: 0.19320155680179596\n",
      "Minibatch loss at step 3650: 0.19606709480285645\n",
      "Minibatch loss at step 3700: 0.15859192609786987\n",
      "Minibatch loss at step 3750: 0.16620096564292908\n",
      "Minibatch loss at step 3800: 0.17317961156368256\n",
      "Minibatch loss at step 3850: 0.21293814480304718\n",
      "Minibatch loss at step 3900: 0.22788414359092712\n",
      "Minibatch loss at step 3950: 0.1950773298740387\n",
      "Minibatch loss at step 4000: 0.2093680500984192\n",
      "Minibatch loss at step 4050: 0.21313512325286865\n",
      "Minibatch loss at step 4100: 0.15134097635746002\n",
      "Minibatch loss at step 4150: 0.17749451100826263\n",
      "Minibatch loss at step 4200: 0.11951209604740143\n",
      "Minibatch loss at step 4250: 0.13090147078037262\n",
      "Minibatch loss at step 4300: 0.12716761231422424\n",
      "Minibatch loss at step 4350: 0.25583189725875854\n",
      "Minibatch loss at step 4400: 0.2933427393436432\n",
      "Minibatch loss at step 4450: 0.30645889043807983\n",
      "Minibatch loss at step 4500: 0.20805254578590393\n",
      "Minibatch loss at step 4550: 0.14267128705978394\n",
      "Minibatch loss at step 4600: 0.27370011806488037\n",
      "Minibatch loss at step 4650: 0.2638491690158844\n",
      "Minibatch loss at step 4700: 0.1653796136379242\n",
      "Minibatch loss at step 4750: 0.1646830141544342\n",
      "Minibatch loss at step 4800: 0.19996073842048645\n",
      "Minibatch loss at step 4850: 0.19044512510299683\n",
      "Minibatch loss at step 4900: 0.14223554730415344\n",
      "Minibatch loss at step 4950: 0.13849061727523804\n",
      "Minibatch loss at step 5000: 0.13375155627727509\n",
      "Minibatch loss at step 5050: 0.15426886081695557\n",
      "Minibatch loss at step 5100: 0.14188560843467712\n",
      "Minibatch loss at step 5150: 0.1783217340707779\n",
      "Minibatch loss at step 5200: 0.214716374874115\n",
      "Minibatch loss at step 5250: 0.1430237740278244\n",
      "Minibatch loss at step 5300: 0.216640442609787\n",
      "Minibatch loss at step 5350: 0.19951757788658142\n",
      "Minibatch loss at step 5400: 0.2969803214073181\n",
      "Minibatch loss at step 5450: 0.19973406195640564\n",
      "Minibatch loss at step 5500: 0.14342516660690308\n",
      "Minibatch loss at step 5550: 0.18093794584274292\n",
      "Minibatch loss at step 5600: 0.1034272313117981\n",
      "Minibatch loss at step 5650: 0.14795368909835815\n",
      "Minibatch loss at step 5700: 0.14803427457809448\n",
      "Minibatch loss at step 5750: 0.14245714247226715\n",
      "Minibatch loss at step 5800: 0.21903115510940552\n",
      "Minibatch loss at step 5850: 0.1118522509932518\n",
      "Minibatch loss at step 5900: 0.22836950421333313\n",
      "Minibatch loss at step 5950: 0.1361074447631836\n",
      "Minibatch loss at step 6000: 0.17744916677474976\n",
      "Minibatch loss at step 6050: 0.1693243682384491\n",
      "Minibatch loss at step 6100: 0.1639382243156433\n",
      "Minibatch loss at step 6150: 0.11941521614789963\n",
      "Minibatch loss at step 6200: 0.18438681960105896\n",
      "Minibatch loss at step 6250: 0.11456815898418427\n",
      "Minibatch loss at step 6300: 0.11712352186441422\n",
      "Minibatch loss at step 6350: 0.10599915683269501\n",
      "Minibatch loss at step 6400: 0.14142954349517822\n",
      "Minibatch loss at step 6450: 0.14264625310897827\n",
      "Minibatch loss at step 6500: 0.11097230762243271\n",
      "Minibatch loss at step 6550: 0.11191575229167938\n",
      "Minibatch loss at step 6600: 0.1856490671634674\n",
      "Minibatch loss at step 6650: 0.19543802738189697\n",
      "Minibatch loss at step 6700: 0.1436740756034851\n",
      "Minibatch loss at step 6750: 0.1274358034133911\n",
      "Minibatch loss at step 6800: 0.12375329434871674\n",
      "Minibatch loss at step 6850: 0.21452222764492035\n",
      "Minibatch loss at step 6900: 0.11287762969732285\n",
      "Minibatch loss at step 6950: 0.11507627367973328\n",
      "Minibatch loss at step 7000: 0.11934088170528412\n",
      "Minibatch loss at step 7050: 0.09338106215000153\n",
      "Minibatch loss at step 7100: 0.08344966918230057\n",
      "Minibatch loss at step 7150: 0.21257519721984863\n",
      "Minibatch loss at step 7200: 0.1194942370057106\n",
      "Minibatch loss at step 7250: 0.11006160080432892\n",
      "Minibatch loss at step 7300: 0.12777943909168243\n",
      "Minibatch loss at step 7350: 0.14213427901268005\n",
      "Minibatch loss at step 7400: 0.12239668518304825\n",
      "Minibatch loss at step 7450: 0.09228572249412537\n",
      "Minibatch loss at step 7500: 0.17859412729740143\n",
      "Minibatch loss at step 7550: 0.1957150101661682\n",
      "Minibatch loss at step 7600: 0.1694321185350418\n",
      "Minibatch loss at step 7650: 0.08650152385234833\n",
      "Minibatch loss at step 7700: 0.10111372172832489\n",
      "Minibatch loss at step 7750: 0.1088978722691536\n",
      "Minibatch loss at step 7800: 0.17066161334514618\n",
      "Minibatch loss at step 7850: 0.11241132766008377\n",
      "Minibatch loss at step 7900: 0.12297573685646057\n",
      "Minibatch loss at step 7950: 0.16080167889595032\n",
      "Minibatch loss at step 8000: 0.08732627332210541\n",
      "Minibatch loss at step 8050: 0.10181821882724762\n",
      "Minibatch loss at step 8100: 0.19098611176013947\n",
      "Minibatch loss at step 8150: 0.18899664282798767\n",
      "Minibatch loss at step 8200: 0.1570308804512024\n",
      "Minibatch loss at step 8250: 0.12530578672885895\n",
      "Minibatch loss at step 8300: 0.163190096616745\n",
      "Minibatch loss at step 8350: 0.06533502042293549\n",
      "Minibatch loss at step 8400: 0.09173454344272614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 8450: 0.08970034122467041\n",
      "Minibatch loss at step 8500: 0.10751761496067047\n",
      "Minibatch loss at step 8550: 0.07702409476041794\n",
      "Minibatch loss at step 8600: 0.16307249665260315\n",
      "Minibatch loss at step 8650: 0.08487161248922348\n",
      "Minibatch loss at step 8700: 0.09559940546751022\n",
      "Minibatch loss at step 8750: 0.13763628900051117\n",
      "Minibatch loss at step 8800: 0.13582879304885864\n",
      "Minibatch loss at step 8850: 0.2363971769809723\n",
      "Minibatch loss at step 8900: 0.08172190189361572\n",
      "Minibatch loss at step 8950: 0.1720668524503708\n",
      "Minibatch loss at step 9000: 0.12464414536952972\n",
      "Minibatch loss at step 9050: 0.14571228623390198\n",
      "Minibatch loss at step 9100: 0.10459545254707336\n",
      "Minibatch loss at step 9150: 0.09517744928598404\n",
      "Minibatch loss at step 9200: 0.19562378525733948\n",
      "Minibatch loss at step 9250: 0.0834466889500618\n",
      "Minibatch loss at step 9300: 0.09832750260829926\n",
      "Minibatch loss at step 9350: 0.1023603081703186\n",
      "Minibatch loss at step 9400: 0.07906140387058258\n",
      "Minibatch loss at step 9450: 0.16521991789340973\n",
      "Minibatch loss at step 9500: 0.07534322887659073\n",
      "Minibatch loss at step 9550: 0.15570519864559174\n",
      "Minibatch loss at step 9600: 0.10949763655662537\n",
      "Minibatch loss at step 9650: 0.08908632397651672\n",
      "Minibatch loss at step 9700: 0.10132749378681183\n",
      "Minibatch loss at step 9750: 0.12954962253570557\n",
      "Minibatch loss at step 9800: 0.11611263453960419\n",
      "Minibatch loss at step 9850: 0.15771889686584473\n",
      "Minibatch loss at step 9900: 0.08972484618425369\n",
      "Minibatch loss at step 9950: 0.07606635987758636\n",
      "Training time: 1421.6174612045288s\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "losses = model.train(train_set, train_label_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: {}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Average test loss: 0.41741710901260376\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    losses = np.array(losses)\n",
    "    np.save('./train_losses_final.npy', losses)\n",
    "    print(losses.shape)\n",
    "except NameError:\n",
    "    losses = np.load('./train_losses_final.npy')\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = losses[:, 0]\n",
    "train_loss = losses[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, 'b-')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training curve\")\n",
    "plt.show()\n",
    "\n",
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "model.test(test_set, test_label_one_hot, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Test sample digit: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network prediction probabilities:\n",
      "[4.0302868e-07 6.5979741e-08 4.3175225e-10 1.2011994e-09 2.8974189e-11\n",
      " 1.7565653e-06 3.2286464e-06 8.0812609e-01 6.8809243e-08 1.9186835e-01]\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "sample = np.expand_dims(test_set[example], axis=0)\n",
    "label = np.expand_dims(test_label_one_hot[example], axis=0)\n",
    "\n",
    "category = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "\n",
    "image = np.reshape(sample, (28, 28))\n",
    "\n",
    "print(\"Test sample category: {}\".format(category))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Test example\")\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 1.0\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax[1].bar(classes, prediction, width, color='Blue')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Network categorical distribution')\n",
    "ax[1].set_xticks(classes)\n",
    "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "ax[1].set_xlabel('category class')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Network prediction probabilities:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time : 1421.6174612045288 s, or  23 min 41.61746120452881 s\n",
      "total parameters involved : 392\n"
     ]
    }
   ],
   "source": [
    "train_time = end_time - start_time\n",
    "print('total training time :', train_time, 's, or ', int(train_time/60), 'min', train_time%60, 's' )\n",
    "count = len(tf.global_variables())\n",
    "print('total parameters involved :', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflow.examples.tutorials.mnist.input_data in tensorflow.examples.tutorials.mnist:\n",
      "\n",
      "NAME\n",
      "    tensorflow.examples.tutorials.mnist.input_data - Functions for downloading and reading MNIST data.\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\user\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py\n",
      "\n",
      "\n",
      "Extracting train_files\\train-images-idx3-ubyte.gz\n",
      "Extracting train_files\\train-labels-idx1-ubyte.gz\n",
      "Extracting train_files\\t10k-images-idx3-ubyte.gz\n",
      "Extracting train_files\\t10k-labels-idx1-ubyte.gz\n",
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001F478B3C588>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001F478B19080>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001F478B19978>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "help(input_data)\n",
    "data = input_data.read_data_sets('train_files')\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "success rate:  88.0\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "i = 0\n",
    "for _ in range(n):\n",
    "    example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "    sample = np.expand_dims(test_set[example], axis=0)\n",
    "    label = np.expand_dims(test_label_one_hot[example], axis=0)\n",
    "\n",
    "    category = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "    feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "        saver.restore(sess, './model')\n",
    "        prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "    p = np.argmax(prediction)\n",
    "    if p == category:\n",
    "        i += 1\n",
    "        \n",
    "print('success rate: ',i/n*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a25c7455adc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset_Reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_celebADataset\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcelebA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys, inspect\n",
    "import time\n",
    "\n",
    "utils_folder = os.path.realpath(\n",
    "    os.path.abspath(os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"..\")))\n",
    "if utils_folder not in sys.path:\n",
    "    sys.path.insert(0, utils_folder)\n",
    "\n",
    "import utils as utils\n",
    "import Dataset_Reader.read_celebADataset as celebA\n",
    "from six.moves import xrange\n",
    "\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir):\n",
    "        celebA_dataset = celebA.read_dataset(data_dir)\n",
    "        self.z_dim = z_dim\n",
    "        self.crop_image_size = crop_image_size\n",
    "        self.resized_image_size = resized_image_size\n",
    "        self.batch_size = batch_size\n",
    "        filename_queue = tf.train.string_input_producer(celebA_dataset.train_images)\n",
    "        self.images = self._read_input_queue(filename_queue)\n",
    "\n",
    "    def _read_input(self, filename_queue):\n",
    "        class DataRecord(object):\n",
    "            pass\n",
    "\n",
    "        reader = tf.WholeFileReader()\n",
    "        key, value = reader.read(filename_queue)\n",
    "        record = DataRecord()\n",
    "        decoded_image = tf.image.decode_jpeg(value,\n",
    "                                             channels=3)  # Assumption:Color images are read and are to be generated\n",
    "\n",
    "        # decoded_image_4d = tf.expand_dims(decoded_image, 0)\n",
    "        # resized_image = tf.image.resize_bilinear(decoded_image_4d, [self.target_image_size, self.target_image_size])\n",
    "        # record.input_image = tf.squeeze(resized_image, squeeze_dims=[0])\n",
    "\n",
    "        cropped_image = tf.cast(\n",
    "            tf.image.crop_to_bounding_box(decoded_image, 55, 35, self.crop_image_size, self.crop_image_size),\n",
    "            tf.float32)\n",
    "        decoded_image_4d = tf.expand_dims(cropped_image, 0)\n",
    "        resized_image = tf.image.resize_bilinear(decoded_image_4d, [self.resized_image_size, self.resized_image_size])\n",
    "        record.input_image = tf.squeeze(resized_image, squeeze_dims=[0])\n",
    "        return record\n",
    "\n",
    "    def _read_input_queue(self, filename_queue):\n",
    "        print(\"Setting up image reader...\")\n",
    "        read_input = self._read_input(filename_queue)\n",
    "        num_preprocess_threads = 4\n",
    "        num_examples_per_epoch = 800\n",
    "        min_queue_examples = int(0.1 * num_examples_per_epoch)\n",
    "        print(\"Shuffling\")\n",
    "        input_image = tf.train.batch([read_input.input_image],\n",
    "                                     batch_size=self.batch_size,\n",
    "                                     num_threads=num_preprocess_threads,\n",
    "                                     capacity=min_queue_examples + 2 * self.batch_size\n",
    "                                     )\n",
    "        input_image = utils.process_image(input_image, 127.5, 127.5)\n",
    "        return input_image\n",
    "\n",
    "    def _generator(self, z, dims, train_phase, activation=tf.nn.relu, scope_name=\"generator\"):\n",
    "        N = len(dims)\n",
    "        image_size = self.resized_image_size // (2 ** (N - 1))\n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            W_z = utils.weight_variable([self.z_dim, dims[0] * image_size * image_size], name=\"W_z\")\n",
    "            b_z = utils.bias_variable([dims[0] * image_size * image_size], name=\"b_z\")\n",
    "            h_z = tf.matmul(z, W_z) + b_z\n",
    "            h_z = tf.reshape(h_z, [-1, image_size, image_size, dims[0]])\n",
    "            h_bnz = utils.batch_norm(h_z, dims[0], train_phase, scope=\"gen_bnz\")\n",
    "            h = activation(h_bnz, name='h_z')\n",
    "            utils.add_activation_summary(h)\n",
    "\n",
    "            for index in range(N - 2):\n",
    "                image_size *= 2\n",
    "                W = utils.weight_variable([5, 5, dims[index + 1], dims[index]], name=\"W_%d\" % index)\n",
    "                b = utils.bias_variable([dims[index + 1]], name=\"b_%d\" % index)\n",
    "                deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[index + 1]])\n",
    "                h_conv_t = utils.conv2d_transpose_strided(h, W, b, output_shape=deconv_shape)\n",
    "                h_bn = utils.batch_norm(h_conv_t, dims[index + 1], train_phase, scope=\"gen_bn%d\" % index)\n",
    "                h = activation(h_bn, name='h_%d' % index)\n",
    "                utils.add_activation_summary(h)\n",
    "\n",
    "            image_size *= 2\n",
    "            W_pred = utils.weight_variable([5, 5, dims[-1], dims[-2]], name=\"W_pred\")\n",
    "            b_pred = utils.bias_variable([dims[-1]], name=\"b_pred\")\n",
    "            deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[-1]])\n",
    "            h_conv_t = utils.conv2d_transpose_strided(h, W_pred, b_pred, output_shape=deconv_shape)\n",
    "            pred_image = tf.nn.tanh(h_conv_t, name='pred_image')\n",
    "            utils.add_activation_summary(pred_image)\n",
    "\n",
    "        return pred_image\n",
    "\n",
    "    def _discriminator(self, input_images, dims, train_phase, activation=tf.nn.relu, scope_name=\"discriminator\",\n",
    "                       scope_reuse=False):\n",
    "        N = len(dims)\n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            if scope_reuse:\n",
    "                scope.reuse_variables()\n",
    "            h = input_images\n",
    "            skip_bn = True  # First layer of discriminator skips batch norm\n",
    "            for index in range(N - 2):\n",
    "                W = utils.weight_variable([5, 5, dims[index], dims[index + 1]], name=\"W_%d\" % index)\n",
    "                b = utils.bias_variable([dims[index + 1]], name=\"b_%d\" % index)\n",
    "                h_conv = utils.conv2d_strided(h, W, b)\n",
    "                if skip_bn:\n",
    "                    h_bn = h_conv\n",
    "                    skip_bn = False\n",
    "                else:\n",
    "                    h_bn = utils.batch_norm(h_conv, dims[index + 1], train_phase, scope=\"disc_bn%d\" % index)\n",
    "                h = activation(h_bn, name=\"h_%d\" % index)\n",
    "                utils.add_activation_summary(h)\n",
    "\n",
    "            shape = h.get_shape().as_list()\n",
    "            image_size = self.resized_image_size // (2 ** (N - 2))  # dims has input dim and output dim\n",
    "            h_reshaped = tf.reshape(h, [self.batch_size, image_size * image_size * shape[3]])\n",
    "            W_pred = utils.weight_variable([image_size * image_size * shape[3], dims[-1]], name=\"W_pred\")\n",
    "            b_pred = utils.bias_variable([dims[-1]], name=\"b_pred\")\n",
    "            h_pred = tf.matmul(h_reshaped, W_pred) + b_pred\n",
    "\n",
    "        return tf.nn.sigmoid(h_pred), h_pred, h\n",
    "\n",
    "    def _cross_entropy_loss(self, logits, labels, name=\"x_entropy\"):\n",
    "        xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits, labels))\n",
    "        tf.scalar_summary(name, xentropy)\n",
    "        return xentropy\n",
    "\n",
    "    def _get_optimizer(self, optimizer_name, learning_rate, optimizer_param):\n",
    "        self.learning_rate = learning_rate\n",
    "        if optimizer_name == \"Adam\":\n",
    "            return tf.train.AdamOptimizer(learning_rate, beta1=optimizer_param)\n",
    "        elif optimizer_name == \"RMSProp\":\n",
    "            return tf.train.RMSPropOptimizer(learning_rate, decay=optimizer_param)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown optimizer %s\" % optimizer_name)\n",
    "\n",
    "    def _train(self, loss_val, var_list, optimizer):\n",
    "        grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n",
    "        for grad, var in grads:\n",
    "            utils.add_gradient_summary(grad, var)\n",
    "        return optimizer.apply_gradients(grads)\n",
    "\n",
    "    def _setup_placeholder(self):\n",
    "        self.train_phase = tf.placeholder(tf.bool)\n",
    "        self.z_vec = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name=\"z\")\n",
    "\n",
    "    def _gan_loss(self, logits_real, logits_fake, feature_real, feature_fake, use_features=False):\n",
    "        discriminator_loss_real = self._cross_entropy_loss(logits_real, tf.ones_like(logits_real),\n",
    "                                                           name=\"disc_real_loss\")\n",
    "\n",
    "        discriminator_loss_fake = self._cross_entropy_loss(logits_fake, tf.zeros_like(logits_fake),\n",
    "                                                           name=\"disc_fake_loss\")\n",
    "        self.discriminator_loss = discriminator_loss_fake + discriminator_loss_real\n",
    "\n",
    "        gen_loss_disc = self._cross_entropy_loss(logits_fake, tf.ones_like(logits_fake), name=\"gen_disc_loss\")\n",
    "        if use_features:\n",
    "            gen_loss_features = tf.reduce_mean(tf.nn.l2_loss(feature_real - feature_fake)) / (self.crop_image_size ** 2)\n",
    "        else:\n",
    "            gen_loss_features = 0\n",
    "        self.gen_loss = gen_loss_disc + 0.1 * gen_loss_features\n",
    "\n",
    "        tf.scalar_summary(\"Discriminator_loss\", self.discriminator_loss)\n",
    "        tf.scalar_summary(\"Generator_loss\", self.gen_loss)\n",
    "\n",
    "    def create_network(self, generator_dims, discriminator_dims, optimizer=\"Adam\", learning_rate=2e-4,\n",
    "                       optimizer_param=0.9, improved_gan_loss=True):\n",
    "        print(\"Setting up model...\")\n",
    "        self._setup_placeholder()\n",
    "        tf.histogram_summary(\"z\", self.z_vec)\n",
    "        self.gen_images = self._generator(self.z_vec, generator_dims, self.train_phase, scope_name=\"generator\")\n",
    "\n",
    "        tf.image_summary(\"image_real\", self.images, max_images=2)\n",
    "        tf.image_summary(\"image_generated\", self.gen_images, max_images=2)\n",
    "\n",
    "        def leaky_relu(x, name=\"leaky_relu\"):\n",
    "            return utils.leaky_relu(x, alpha=0.2, name=name)\n",
    "\n",
    "        discriminator_real_prob, logits_real, feature_real = self._discriminator(self.images, discriminator_dims,\n",
    "                                                                                 self.train_phase,\n",
    "                                                                                 activation=leaky_relu,\n",
    "                                                                                 scope_name=\"discriminator\",\n",
    "                                                                                 scope_reuse=False)\n",
    "\n",
    "        discriminator_fake_prob, logits_fake, feature_fake = self._discriminator(self.gen_images, discriminator_dims,\n",
    "                                                                                 self.train_phase,\n",
    "                                                                                 activation=leaky_relu,\n",
    "                                                                                 scope_name=\"discriminator\",\n",
    "                                                                                 scope_reuse=True)\n",
    "\n",
    "        # utils.add_activation_summary(tf.identity(discriminator_real_prob, name='disc_real_prob'))\n",
    "        # utils.add_activation_summary(tf.identity(discriminator_fake_prob, name='disc_fake_prob'))\n",
    "\n",
    "        # Loss calculation\n",
    "        self._gan_loss(logits_real, logits_fake, feature_real, feature_fake, use_features=improved_gan_loss)\n",
    "\n",
    "        train_variables = tf.trainable_variables()\n",
    "\n",
    "        for v in train_variables:\n",
    "            # print (v.op.name)\n",
    "            utils.add_to_regularization_and_summary(var=v)\n",
    "\n",
    "        self.generator_variables = [v for v in train_variables if v.name.startswith(\"generator\")]\n",
    "        # print(map(lambda x: x.op.name, generator_variables))\n",
    "        self.discriminator_variables = [v for v in train_variables if v.name.startswith(\"discriminator\")]\n",
    "        # print(map(lambda x: x.op.name, discriminator_variables))\n",
    "\n",
    "        optim = self._get_optimizer(optimizer, learning_rate, optimizer_param)\n",
    "\n",
    "        self.generator_train_op = self._train(self.gen_loss, self.generator_variables, optim)\n",
    "        self.discriminator_train_op = self._train(self.discriminator_loss, self.discriminator_variables, optim)\n",
    "\n",
    "    def initialize_network(self, logs_dir):\n",
    "        print(\"Initializing network...\")\n",
    "        self.logs_dir = logs_dir\n",
    "        self.sess = tf.Session()\n",
    "        self.summary_op = tf.merge_all_summaries()\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.summary_writer = tf.train.SummaryWriter(self.logs_dir, self.sess.graph)\n",
    "\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "        ckpt = tf.train.get_checkpoint_state(self.logs_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            self.saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "            print(\"Model restored...\")\n",
    "        self.coord = tf.train.Coordinator()\n",
    "        self.threads = tf.train.start_queue_runners(self.sess, self.coord)\n",
    "\n",
    "    def train_model(self, max_iterations):\n",
    "        try:\n",
    "            print(\"Training model...\")\n",
    "            for itr in xrange(1, max_iterations):\n",
    "                batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n",
    "                feed_dict = {self.z_vec: batch_z, self.train_phase: True}\n",
    "\n",
    "                self.sess.run(self.discriminator_train_op, feed_dict=feed_dict)\n",
    "                self.sess.run(self.generator_train_op, feed_dict=feed_dict)\n",
    "\n",
    "                if itr % 10 == 0:\n",
    "                    g_loss_val, d_loss_val, summary_str = self.sess.run(\n",
    "                        [self.gen_loss, self.discriminator_loss, self.summary_op], feed_dict=feed_dict)\n",
    "                    print(\"Step: %d, generator loss: %g, discriminator_loss: %g\" % (itr, g_loss_val, d_loss_val))\n",
    "                    self.summary_writer.add_summary(summary_str, itr)\n",
    "\n",
    "                if itr % 2000 == 0:\n",
    "                    self.saver.save(self.sess, self.logs_dir + \"model.ckpt\", global_step=itr)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Ending Training...\")\n",
    "        finally:\n",
    "            self.coord.request_stop()\n",
    "            self.coord.join(self.threads)  # Wait for threads to finish.\n",
    "\n",
    "    def visualize_model(self):\n",
    "        print(\"Sampling images from model...\")\n",
    "        batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n",
    "        feed_dict = {self.z_vec: batch_z, self.train_phase: False}\n",
    "\n",
    "        images = self.sess.run(self.gen_images, feed_dict=feed_dict)\n",
    "        images = utils.unprocess_image(images, 127.5, 127.5).astype(np.uint8)\n",
    "        shape = [4, self.batch_size // 4]\n",
    "        utils.save_imshow_grid(images, self.logs_dir, \"generated.png\", shape=shape)\n",
    "\n",
    "\n",
    "class WasserstienGAN(GAN):\n",
    "    def __init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir, clip_values=(-0.01, 0.01),\n",
    "                 critic_iterations=5):\n",
    "        self.critic_iterations = critic_iterations\n",
    "        self.clip_values = clip_values\n",
    "        GAN.__init__(self, z_dim, crop_image_size, resized_image_size, batch_size, data_dir)\n",
    "\n",
    "    def _generator(self, z, dims, train_phase, activation=tf.nn.relu, scope_name=\"generator\"):\n",
    "        N = len(dims)\n",
    "        image_size = self.resized_image_size // (2 ** (N - 1))\n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            W_z = utils.weight_variable([self.z_dim, dims[0] * image_size * image_size], name=\"W_z\")\n",
    "            h_z = tf.matmul(z, W_z)\n",
    "            h_z = tf.reshape(h_z, [-1, image_size, image_size, dims[0]])\n",
    "            h_bnz = utils.batch_norm(h_z, dims[0], train_phase, scope=\"gen_bnz\")\n",
    "            h = activation(h_bnz, name='h_z')\n",
    "            utils.add_activation_summary(h)\n",
    "\n",
    "            for index in range(N - 2):\n",
    "                image_size *= 2\n",
    "                W = utils.weight_variable([4, 4, dims[index + 1], dims[index]], name=\"W_%d\" % index)\n",
    "                b = tf.zeros([dims[index + 1]])\n",
    "                deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[index + 1]])\n",
    "                h_conv_t = utils.conv2d_transpose_strided(h, W, b, output_shape=deconv_shape)\n",
    "                h_bn = utils.batch_norm(h_conv_t, dims[index + 1], train_phase, scope=\"gen_bn%d\" % index)\n",
    "                h = activation(h_bn, name='h_%d' % index)\n",
    "                utils.add_activation_summary(h)\n",
    "\n",
    "            image_size *= 2\n",
    "            W_pred = utils.weight_variable([4, 4, dims[-1], dims[-2]], name=\"W_pred\")\n",
    "            b = tf.zeros([dims[-1]])\n",
    "            deconv_shape = tf.pack([tf.shape(h)[0], image_size, image_size, dims[-1]])\n",
    "            h_conv_t = utils.conv2d_transpose_strided(h, W_pred, b, output_shape=deconv_shape)\n",
    "            pred_image = tf.nn.tanh(h_conv_t, name='pred_image')\n",
    "            utils.add_activation_summary(pred_image)\n",
    "\n",
    "        return pred_image\n",
    "\n",
    "    def _discriminator(self, input_images, dims, train_phase, activation=tf.nn.relu, scope_name=\"discriminator\",\n",
    "                       scope_reuse=False):\n",
    "        N = len(dims)\n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            if scope_reuse:\n",
    "                scope.reuse_variables()\n",
    "            h = input_images\n",
    "            skip_bn = True  # First layer of discriminator skips batch norm\n",
    "            for index in range(N - 2):\n",
    "                W = utils.weight_variable([4, 4, dims[index], dims[index + 1]], name=\"W_%d\" % index)\n",
    "                b = tf.zeros([dims[index+1]])\n",
    "                h_conv = utils.conv2d_strided(h, W, b)\n",
    "                if skip_bn:\n",
    "                    h_bn = h_conv\n",
    "                    skip_bn = False\n",
    "                else:\n",
    "                    h_bn = utils.batch_norm(h_conv, dims[index + 1], train_phase, scope=\"disc_bn%d\" % index)\n",
    "                h = activation(h_bn, name=\"h_%d\" % index)\n",
    "                utils.add_activation_summary(h)\n",
    "\n",
    "            W_pred = utils.weight_variable([4, 4, dims[-2], dims[-1]], name=\"W_pred\")\n",
    "            b = tf.zeros([dims[-1]])\n",
    "            h_pred = utils.conv2d_strided(h, W_pred, b)\n",
    "        return None, h_pred, None  # Return the last convolution output. None values are returned to maintatin disc from other GAN\n",
    "\n",
    "    def _gan_loss(self, logits_real, logits_fake, feature_real, feature_fake, use_features=False):\n",
    "        self.discriminator_loss = tf.reduce_mean(logits_real - logits_fake)\n",
    "        self.gen_loss = tf.reduce_mean(logits_fake)\n",
    "\n",
    "        tf.scalar_summary(\"Discriminator_loss\", self.discriminator_loss)\n",
    "        tf.scalar_summary(\"Generator_loss\", self.gen_loss)\n",
    "\n",
    "    def train_model(self, max_iterations):\n",
    "        try:\n",
    "            print(\"Training Wasserstein GAN model...\")\n",
    "            clip_discriminator_var_op = [var.assign(tf.clip_by_value(var, self.clip_values[0], self.clip_values[1])) for\n",
    "                                         var in self.discriminator_variables]\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            def get_feed_dict(train_phase=True):\n",
    "                batch_z = np.random.uniform(-1.0, 1.0, size=[self.batch_size, self.z_dim]).astype(np.float32)\n",
    "                feed_dict = {self.z_vec: batch_z, self.train_phase: train_phase}\n",
    "                return feed_dict\n",
    "\n",
    "            for itr in xrange(1, max_iterations):\n",
    "                if itr < 25 or itr % 500 == 0:\n",
    "                    critic_itrs = 25\n",
    "                else:\n",
    "                    critic_itrs = self.critic_iterations\n",
    "\n",
    "                for critic_itr in range(critic_itrs):\n",
    "                    self.sess.run(self.discriminator_train_op, feed_dict=get_feed_dict(True))\n",
    "                    self.sess.run(clip_discriminator_var_op)\n",
    "\n",
    "                feed_dict = get_feed_dict(True)\n",
    "                self.sess.run(self.generator_train_op, feed_dict=feed_dict)\n",
    "\n",
    "                if itr % 100 == 0:\n",
    "                    summary_str = self.sess.run(self.summary_op, feed_dict=feed_dict)\n",
    "                    self.summary_writer.add_summary(summary_str, itr)\n",
    "\n",
    "                if itr % 200 == 0:\n",
    "                    stop_time = time.time()\n",
    "                    duration = (stop_time - start_time) / 200.0\n",
    "                    start_time = stop_time\n",
    "                    g_loss_val, d_loss_val = self.sess.run([self.gen_loss, self.discriminator_loss],\n",
    "                                                           feed_dict=feed_dict)\n",
    "                    print(\"Time: %g/itr, Step: %d, generator loss: %g, discriminator_loss: %g\" % (\n",
    "                        duration, itr, g_loss_val, d_loss_val))\n",
    "\n",
    "                if itr % 5000 == 0:\n",
    "                    self.saver.save(self.sess, self.logs_dir + \"model.ckpt\", global_step=itr)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Ending Training...\")\n",
    "        finally:\n",
    "            self.coord.request_stop()\n",
    "            self.coord.join(self.threads)  # Wait for threads to finish."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
