{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weihao_assignment3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tayA7r2uNUxD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Assignment 3\n",
        "\n",
        "##Convolutional neural network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ql_ZJQkXTpYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "    \n",
        "    '''extract file from MNIST file and seperate label and training file'''\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 28, 28)\n",
        "\n",
        "    return images, labels\n",
        "  \n",
        "\n",
        "train_X, train_Y = load_mnist('', kind='train')\n",
        "test_X, test_Y = load_mnist('', kind='t10k')\n",
        "\n",
        "train_set = np.expand_dims(train_X, axis=3)\n",
        "train_label = np.expand_dims(train_Y, axis=1)\n",
        "test_set = np.expand_dims(test_X, axis=3)\n",
        "test_label = np.expand_dims(test_Y, axis=1)\n",
        "\n",
        "n_train = len(train_set)\n",
        "n_test = len(test_set)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmV-xfsWTpY-",
        "colab_type": "code",
        "outputId": "0a4b1adb-016b-400b-a4fe-97cbb6054c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "def one_hot(labels):\n",
        "    \"\"\"\n",
        "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
        "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "    \n",
        "    \"\"\"\n",
        "    labels = np.squeeze(labels)\n",
        "    one_hot_labels = []\n",
        "    for num in labels:\n",
        "        one_hot = [0.0] * 10\n",
        "        if num == 10:\n",
        "            one_hot[0] = 1.0\n",
        "        else:\n",
        "            one_hot[num] = 1.0\n",
        "        one_hot_labels.append(one_hot)\n",
        "    labels = np.array(one_hot_labels).astype(np.float32)\n",
        "    return labels\n",
        "\n",
        "train_label_one_hot = one_hot(train_label)\n",
        "test_label_one_hot = one_hot(test_label)\n",
        "\n",
        "print(train_label_one_hot.shape)\n",
        "print(test_label_one_hot.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i48PefM8Rsgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Parameters\n",
        "\n",
        "Convolutional layer:\n",
        "\n",
        "- first layer: filters:32, kernel size: 11x11, strides:4\n",
        "- second layer: filters:64, kernel size: 5x5, strides:1\n",
        "- third layer: filters:64, kernel size: 5x5, strides:1\n",
        "\n",
        "Down sample:\n",
        "- pooling size: 2, strides: 2\n",
        "\n",
        "Dropout rate: 0.25"
      ]
    },
    {
      "metadata": {
        "id": "6mbxTZDgTpZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SVHN_CNN:\n",
        "    def __init__(self, wd_factor, learning_rate): #initialize all the variable to be used in the other functions\n",
        "        self.wd_factor = wd_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.train_pointer = 0\n",
        "        self.test_pointer = 0\n",
        "        \n",
        "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='input') #to make a 28 times 28 minipatch swipe\n",
        "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
        "        \n",
        "        # For batch norm and dropout\n",
        "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
        "        print(self.input)\n",
        "        \n",
        "        self._build_graph()\n",
        "        \n",
        "    def _build_graph(self):\n",
        "        weights = []  # for weight decay\n",
        "        \n",
        "        with tf.variable_scope('layers'):\n",
        "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
        "                                 data_format='channels_last', activation=None, use_bias=True,\n",
        "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
        "            print(h)\n",
        "            \n",
        "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
        "            h = tf.nn.relu(h)\n",
        "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
        "                                 data_format='channels_last', activation=None, use_bias=True,\n",
        "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
        "            \n",
        "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
        "            h = tf.nn.relu(h)\n",
        "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
        "                                 data_format='channels_last', activation=None, use_bias=True,\n",
        "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
        "            \n",
        "            # Downsample\n",
        "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
        "            print(h)\n",
        "            \n",
        "            # Fully connected layers\n",
        "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
        "            h = tf.nn.relu(h)\n",
        "            h = tf.layers.flatten(h)\n",
        "            print(h)\n",
        "            \n",
        "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
        "                                activation=tf.nn.relu, name='dense1')\n",
        "            print(h)\n",
        "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
        "            print(h)\n",
        "            \n",
        "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
        "                                          activation=tf.identity, name='dense2')\n",
        "            print(self.logits)\n",
        "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
        "            \n",
        "        with tf.name_scope('loss'):\n",
        "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
        "                                                                                  labels=self.ground_truth))\n",
        "            self.loss += self.weight_decay()\n",
        "            \n",
        "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "        \n",
        "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        with tf.control_dependencies(update_ops):\n",
        "            self.train_op = self.optimizer.minimize(self.loss)\n",
        "            \n",
        "    def weight_decay(self):\n",
        "        loss = 0\n",
        "        for v in tf.global_variables():\n",
        "            if 'Adam' in v.name:\n",
        "                continue\n",
        "            elif 'kernel' in v.name:\n",
        "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
        "        print(loss)\n",
        "        return loss\n",
        "    \n",
        "    def train_minibatch(self, samples, labels, batch_size):\n",
        "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
        "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
        "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
        "            self.train_pointer += batch_size\n",
        "        else:\n",
        "            samples_minibatch = samples[self.train_pointer:]\n",
        "            labels_minibatch = labels[self.train_pointer:]\n",
        "            self.train_pointer = 0\n",
        "        return samples_minibatch, labels_minibatch\n",
        "\n",
        "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
        "        print('Start Training')\n",
        "        losses = []\n",
        "        \n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            saver = tf.train.Saver()\n",
        "            \n",
        "            for i in range(iteration_steps):\n",
        "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
        "                \n",
        "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
        "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
        "                \n",
        "                if i % 50 == 0:\n",
        "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
        "                    losses.append([i, loss])\n",
        "                    \n",
        "            saver.save(sess, './model')\n",
        "        return losses\n",
        "                    \n",
        "    def test_minibatch(self, samples, labels, batch_size):\n",
        "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
        "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
        "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
        "            self.test_pointer += batch_size\n",
        "            end_of_epoch = False\n",
        "        else:\n",
        "            samples_minibatch = samples[self.test_pointer:]\n",
        "            labels_minibatch = labels[self.test_pointer:]\n",
        "            self.test_pointer = 0\n",
        "            end_of_epoch = True\n",
        "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
        "            \n",
        "    def test(self, test_samples, test_labels, test_batch_size):\n",
        "        self.test_pointer = 0\n",
        "        end_of_epoch = False\n",
        "        losses = []\n",
        "        \n",
        "        with tf.Session() as sess:\n",
        "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
        "            saver.restore(sess, './model')\n",
        "            while not end_of_epoch:\n",
        "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
        "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
        "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
        "        print(\"Average test loss: {}\".format(np.mean(losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8jEwQeuTpZP",
        "colab_type": "code",
        "outputId": "a41d2614-4540-4e1a-a1f6-5fa8d81c6a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "WD_FACTOR = 0.0\n",
        "LEARNING_RATE = 0.001\n",
        "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
            "Tensor(\"layers/pool1/MaxPool:0\", shape=(?, 3, 3, 64), dtype=float32)\n",
            "Tensor(\"layers/flatten/Reshape:0\", shape=(?, 576), dtype=float32)\n",
            "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
            "Tensor(\"layers/dropout1/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
            "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
            "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mNL8Hwz4TpZa",
        "colab_type": "code",
        "outputId": "cacbb415-4d38-44e0-e1d5-36e6e1548338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "cell_type": "code",
      "source": [
        "tf.global_variables()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'layers/conv1/kernel:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/kernel:0' shape=(576, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
              " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(576, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(576, 32) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
              " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "NDtb29OrTpZn",
        "colab_type": "code",
        "outputId": "6c947c9e-633f-4cfb-fb85-1ae2f2b6b63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 128\n",
        "ITERATIONS = 10000\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "losses = model.train(train_set, train_label_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Training time: {}s\".format(end_time - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Minibatch loss at step 0: 2.5582613945007324\n",
            "Minibatch loss at step 50: 0.34103575348854065\n",
            "Minibatch loss at step 100: 0.27529269456863403\n",
            "Minibatch loss at step 150: 0.23236215114593506\n",
            "Minibatch loss at step 200: 0.22255456447601318\n",
            "Minibatch loss at step 250: 0.2114444524049759\n",
            "Minibatch loss at step 300: 0.1589864194393158\n",
            "Minibatch loss at step 350: 0.11716384440660477\n",
            "Minibatch loss at step 400: 0.15190276503562927\n",
            "Minibatch loss at step 450: 0.17660868167877197\n",
            "Minibatch loss at step 500: 0.10386887192726135\n",
            "Minibatch loss at step 550: 0.035237349569797516\n",
            "Minibatch loss at step 600: 0.07842843979597092\n",
            "Minibatch loss at step 650: 0.06903687864542007\n",
            "Minibatch loss at step 700: 0.06841865926980972\n",
            "Minibatch loss at step 750: 0.12218177318572998\n",
            "Minibatch loss at step 800: 0.0682360902428627\n",
            "Minibatch loss at step 850: 0.032321833074092865\n",
            "Minibatch loss at step 900: 0.06667044758796692\n",
            "Minibatch loss at step 950: 0.06887619197368622\n",
            "Minibatch loss at step 1000: 0.05163899436593056\n",
            "Minibatch loss at step 1050: 0.0834563821554184\n",
            "Minibatch loss at step 1100: 0.1779477596282959\n",
            "Minibatch loss at step 1150: 0.12404676526784897\n",
            "Minibatch loss at step 1200: 0.022228248417377472\n",
            "Minibatch loss at step 1250: 0.027272585779428482\n",
            "Minibatch loss at step 1300: 0.0687132328748703\n",
            "Minibatch loss at step 1350: 0.07689060270786285\n",
            "Minibatch loss at step 1400: 0.0032033734023571014\n",
            "Minibatch loss at step 1450: 0.023693930357694626\n",
            "Minibatch loss at step 1500: 0.06360968202352524\n",
            "Minibatch loss at step 1550: 0.07193078100681305\n",
            "Minibatch loss at step 1600: 0.05200265720486641\n",
            "Minibatch loss at step 1650: 0.05148899927735329\n",
            "Minibatch loss at step 1700: 0.0210486501455307\n",
            "Minibatch loss at step 1750: 0.03334403783082962\n",
            "Minibatch loss at step 1800: 0.08851256966590881\n",
            "Minibatch loss at step 1850: 0.051691628992557526\n",
            "Minibatch loss at step 1900: 0.011373404413461685\n",
            "Minibatch loss at step 1950: 0.04790005087852478\n",
            "Minibatch loss at step 2000: 0.0399555079638958\n",
            "Minibatch loss at step 2050: 0.02172982506453991\n",
            "Minibatch loss at step 2100: 0.0372561551630497\n",
            "Minibatch loss at step 2150: 0.011211693286895752\n",
            "Minibatch loss at step 2200: 0.05281199887394905\n",
            "Minibatch loss at step 2250: 0.014870928600430489\n",
            "Minibatch loss at step 2300: 0.05299225449562073\n",
            "Minibatch loss at step 2350: 0.021685373038053513\n",
            "Minibatch loss at step 2400: 0.03775317594408989\n",
            "Minibatch loss at step 2450: 0.03111211210489273\n",
            "Minibatch loss at step 2500: 0.022575482726097107\n",
            "Minibatch loss at step 2550: 0.008796213194727898\n",
            "Minibatch loss at step 2600: 0.013042263686656952\n",
            "Minibatch loss at step 2650: 0.0023030259180814028\n",
            "Minibatch loss at step 2700: 0.05227885767817497\n",
            "Minibatch loss at step 2750: 0.07186141610145569\n",
            "Minibatch loss at step 2800: 0.003304275218397379\n",
            "Minibatch loss at step 2850: 0.01804429106414318\n",
            "Minibatch loss at step 2900: 0.0152667798101902\n",
            "Minibatch loss at step 2950: 0.006872369907796383\n",
            "Minibatch loss at step 3000: 0.06987747550010681\n",
            "Minibatch loss at step 3050: 0.008361735381186008\n",
            "Minibatch loss at step 3100: 0.019472014158964157\n",
            "Minibatch loss at step 3150: 0.06186187267303467\n",
            "Minibatch loss at step 3200: 0.02064434625208378\n",
            "Minibatch loss at step 3250: 0.028863873332738876\n",
            "Minibatch loss at step 3300: 0.011636490002274513\n",
            "Minibatch loss at step 3350: 0.018955092877149582\n",
            "Minibatch loss at step 3400: 0.007100715301930904\n",
            "Minibatch loss at step 3450: 0.05420985445380211\n",
            "Minibatch loss at step 3500: 0.019302241504192352\n",
            "Minibatch loss at step 3550: 0.0032308106310665607\n",
            "Minibatch loss at step 3600: 0.02125401794910431\n",
            "Minibatch loss at step 3650: 0.026695996522903442\n",
            "Minibatch loss at step 3700: 0.042310092598199844\n",
            "Minibatch loss at step 3750: 0.00037933755083940923\n",
            "Minibatch loss at step 3800: 0.042942821979522705\n",
            "Minibatch loss at step 3850: 0.009384015575051308\n",
            "Minibatch loss at step 3900: 0.011424802243709564\n",
            "Minibatch loss at step 3950: 0.0014031981118023396\n",
            "Minibatch loss at step 4000: 0.015032757073640823\n",
            "Minibatch loss at step 4050: 0.015264834277331829\n",
            "Minibatch loss at step 4100: 0.002929211361333728\n",
            "Minibatch loss at step 4150: 0.016977231949567795\n",
            "Minibatch loss at step 4200: 0.002792204264551401\n",
            "Minibatch loss at step 4250: 0.015076542273163795\n",
            "Minibatch loss at step 4300: 0.04712706804275513\n",
            "Minibatch loss at step 4350: 0.0010481789940968156\n",
            "Minibatch loss at step 4400: 0.00091412418987602\n",
            "Minibatch loss at step 4450: 0.004459105897694826\n",
            "Minibatch loss at step 4500: 0.010475469753146172\n",
            "Minibatch loss at step 4550: 0.02382221259176731\n",
            "Minibatch loss at step 4600: 0.005908540450036526\n",
            "Minibatch loss at step 4650: 0.020680677145719528\n",
            "Minibatch loss at step 4700: 0.006727383006364107\n",
            "Minibatch loss at step 4750: 0.023883456364274025\n",
            "Minibatch loss at step 4800: 0.002757561858743429\n",
            "Minibatch loss at step 4850: 0.0019065876258537173\n",
            "Minibatch loss at step 4900: 0.0038518428336828947\n",
            "Minibatch loss at step 4950: 0.023557748645544052\n",
            "Minibatch loss at step 5000: 0.014982042834162712\n",
            "Minibatch loss at step 5050: 0.009380397386848927\n",
            "Minibatch loss at step 5100: 0.015364713966846466\n",
            "Minibatch loss at step 5150: 0.0003947056829929352\n",
            "Minibatch loss at step 5200: 0.004821703769266605\n",
            "Minibatch loss at step 5250: 0.007371810730546713\n",
            "Minibatch loss at step 5300: 0.0025259098038077354\n",
            "Minibatch loss at step 5350: 0.009758281521499157\n",
            "Minibatch loss at step 5400: 0.0178841482847929\n",
            "Minibatch loss at step 5450: 0.007370541337877512\n",
            "Minibatch loss at step 5500: 0.019526664167642593\n",
            "Minibatch loss at step 5550: 0.008762294426560402\n",
            "Minibatch loss at step 5600: 0.007363746874034405\n",
            "Minibatch loss at step 5650: 0.007609101012349129\n",
            "Minibatch loss at step 5700: 0.013127441518008709\n",
            "Minibatch loss at step 5750: 0.013301701284945011\n",
            "Minibatch loss at step 5800: 0.0016950308345258236\n",
            "Minibatch loss at step 5850: 0.012649941258132458\n",
            "Minibatch loss at step 5900: 0.011769410222768784\n",
            "Minibatch loss at step 5950: 0.06891993433237076\n",
            "Minibatch loss at step 6000: 0.012450441718101501\n",
            "Minibatch loss at step 6050: 0.029809588566422462\n",
            "Minibatch loss at step 6100: 0.01584559865295887\n",
            "Minibatch loss at step 6150: 0.04578873887658119\n",
            "Minibatch loss at step 6200: 0.0026960615068674088\n",
            "Minibatch loss at step 6250: 0.006058539263904095\n",
            "Minibatch loss at step 6300: 0.0019594121258705854\n",
            "Minibatch loss at step 6350: 0.04216321185231209\n",
            "Minibatch loss at step 6400: 0.03698136657476425\n",
            "Minibatch loss at step 6450: 0.0038927136920392513\n",
            "Minibatch loss at step 6500: 0.001838693511672318\n",
            "Minibatch loss at step 6550: 0.005996497347950935\n",
            "Minibatch loss at step 6600: 0.017367668449878693\n",
            "Minibatch loss at step 6650: 0.02188088372349739\n",
            "Minibatch loss at step 6700: 0.054912883788347244\n",
            "Minibatch loss at step 6750: 0.0017343803774565458\n",
            "Minibatch loss at step 6800: 0.01878254860639572\n",
            "Minibatch loss at step 6850: 0.02617746591567993\n",
            "Minibatch loss at step 6900: 0.02545655146241188\n",
            "Minibatch loss at step 6950: 0.048996541649103165\n",
            "Minibatch loss at step 7000: 0.029303791001439095\n",
            "Minibatch loss at step 7050: 0.02412349544465542\n",
            "Minibatch loss at step 7100: 0.011528566479682922\n",
            "Minibatch loss at step 7150: 0.0014162810984998941\n",
            "Minibatch loss at step 7200: 0.01321839913725853\n",
            "Minibatch loss at step 7250: 0.0013228274183347821\n",
            "Minibatch loss at step 7300: 0.00045899528777226806\n",
            "Minibatch loss at step 7350: 0.004089600406587124\n",
            "Minibatch loss at step 7400: 0.03083566203713417\n",
            "Minibatch loss at step 7450: 0.01907775178551674\n",
            "Minibatch loss at step 7500: 0.00030117269488982856\n",
            "Minibatch loss at step 7550: 0.002538519911468029\n",
            "Minibatch loss at step 7600: 0.003498584497720003\n",
            "Minibatch loss at step 7650: 0.0039597912691533566\n",
            "Minibatch loss at step 7700: 0.0028256094083189964\n",
            "Minibatch loss at step 7750: 0.011246818117797375\n",
            "Minibatch loss at step 7800: 0.001595039153471589\n",
            "Minibatch loss at step 7850: 0.004462333861738443\n",
            "Minibatch loss at step 7900: 0.009493328630924225\n",
            "Minibatch loss at step 7950: 0.006684421561658382\n",
            "Minibatch loss at step 8000: 0.010966558009386063\n",
            "Minibatch loss at step 8050: 0.014328433200716972\n",
            "Minibatch loss at step 8100: 0.0015913927927613258\n",
            "Minibatch loss at step 8150: 0.0039042490534484386\n",
            "Minibatch loss at step 8200: 0.0026206281036138535\n",
            "Minibatch loss at step 8250: 0.013291099108755589\n",
            "Minibatch loss at step 8300: 0.025989476591348648\n",
            "Minibatch loss at step 8350: 0.016931772232055664\n",
            "Minibatch loss at step 8400: 0.0027440288104116917\n",
            "Minibatch loss at step 8450: 0.0016018034657463431\n",
            "Minibatch loss at step 8500: 0.0002753066655714065\n",
            "Minibatch loss at step 8550: 0.03542226180434227\n",
            "Minibatch loss at step 8600: 0.009759225882589817\n",
            "Minibatch loss at step 8650: 0.11418439447879791\n",
            "Minibatch loss at step 8700: 0.000925133703276515\n",
            "Minibatch loss at step 8750: 0.008005354553461075\n",
            "Minibatch loss at step 8800: 0.004079368431121111\n",
            "Minibatch loss at step 8850: 0.0036029284819960594\n",
            "Minibatch loss at step 8900: 0.00472994614392519\n",
            "Minibatch loss at step 8950: 0.013062691316008568\n",
            "Minibatch loss at step 9000: 0.001470854040235281\n",
            "Minibatch loss at step 9050: 0.006441798061132431\n",
            "Minibatch loss at step 9100: 0.021205129101872444\n",
            "Minibatch loss at step 9150: 0.0010935569880530238\n",
            "Minibatch loss at step 9200: 0.02395785227417946\n",
            "Minibatch loss at step 9250: 0.0010655163787305355\n",
            "Minibatch loss at step 9300: 0.041601963341236115\n",
            "Minibatch loss at step 9350: 0.005876083858311176\n",
            "Minibatch loss at step 9400: 0.04349786788225174\n",
            "Minibatch loss at step 9450: 0.019831068813800812\n",
            "Minibatch loss at step 9500: 0.02327052876353264\n",
            "Minibatch loss at step 9550: 0.0012287030695006251\n",
            "Minibatch loss at step 9600: 0.0027259867638349533\n",
            "Minibatch loss at step 9650: 0.000894804485142231\n",
            "Minibatch loss at step 9700: 0.0013812993420287967\n",
            "Minibatch loss at step 9750: 0.005373929627239704\n",
            "Minibatch loss at step 9800: 0.003953625448048115\n",
            "Minibatch loss at step 9850: 0.023540036752820015\n",
            "Minibatch loss at step 9900: 0.0016267059836536646\n",
            "Minibatch loss at step 9950: 0.021292466670274734\n",
            "Training time: 89.0249514579773s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5UwByGAKTpZy",
        "colab_type": "code",
        "outputId": "d73d8b4c-585e-4493-c365-204a3efe0c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    losses = np.array(losses)\n",
        "    np.save('./train_losses.npy', losses)\n",
        "    print(losses.shape)\n",
        "except NameError:\n",
        "    losses = np.load('./train_losses.npy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2wQK47N8TpZ-",
        "colab_type": "code",
        "outputId": "d3249a44-b902-49df-9632-768a35557d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iterations = losses[:, 0]\n",
        "train_loss = losses[:, 1]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_loss, 'b-')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training curve\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAFMCAYAAAD1Fdm1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGuS5CgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f29b01c7668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3Bqok8HETpaM",
        "colab_type": "code",
        "outputId": "dfb84266-9fa1-451b-bcb4-ff8710a9d7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_BATCH_SIZE = 128\n",
        "\n",
        "model.test(test_set, test_label_one_hot, TEST_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "Average test loss: 0.05543876439332962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-cW8432PTpaY",
        "colab_type": "code",
        "outputId": "b8871f4e-22e9-4a5e-d85d-b9ece3228a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "cell_type": "code",
      "source": [
        "example = np.random.choice(np.arange(n_test))\n",
        "\n",
        "sample = np.expand_dims(test_set[example], axis=0)\n",
        "label = np.expand_dims(test_label_one_hot[example], axis=0)\n",
        "\n",
        "digit = np.where(label[0]==1.0)[0][0]\n",
        "\n",
        "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
        "    saver.restore(sess, './model')\n",
        "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
        "\n",
        "image = np.reshape(sample, (28, 28))\n",
        "\n",
        "print(\"Test sample digit: {}\".format(digit))\n",
        "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
        "ax[0].imshow(image, cmap='gray')\n",
        "ax[0].set_title(\"Test example\")\n",
        "\n",
        "classes = np.arange(10)\n",
        "width = 1.0\n",
        "\n",
        "#fig, ax = plt.subplots()\n",
        "ax[1].bar(classes, prediction, width, color='Blue')\n",
        "ax[1].set_ylabel('Probabilities')\n",
        "ax[1].set_title('Network categorical distribution')\n",
        "ax[1].set_xticks(classes)\n",
        "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
        "ax[1].set_xlabel('Digit class')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"Network prediction probabilities:\")\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "Test sample digit: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAFMCAYAAAB8qBn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAIAAAR7AJgKczdVwSfLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f299bc86fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Network prediction probabilities:\n",
            "[4.0883866e-21 7.3330529e-18 4.7990066e-15 1.0000000e+00 2.1179628e-21\n",
            " 2.7741432e-11 8.3799156e-25 1.7318102e-12 5.1510363e-12 6.2179062e-10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ge2ysWxTpaj",
        "colab_type": "code",
        "outputId": "2826b84a-e519-4aa5-9da5-0800c211f8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_time = end_time - start_time\n",
        "print('total training time :', train_time, 's, or ', int(train_time/60), 'min', train_time%60, 's' )\n",
        "count = len(tf.global_variables())\n",
        "print('total parameters involved :', count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training time : 89.0249514579773 s, or  1 min 29.024951457977295 s\n",
            "total parameters involved : 168\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}