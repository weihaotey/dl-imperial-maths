{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    '''A function to read idx file format into numpy array'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
    "    \n",
    "train_set = read_idx('train-images-idx3-ubyte.mat')\n",
    "train_set = np.expand_dims(train_set, axis=3)\n",
    "print(train_set.shape)\n",
    "train_label = read_idx('train-labels-idx1-ubyte.mat')\n",
    "train_label = np.expand_dims(train_label, axis=1)\n",
    "print(train_label.shape)\n",
    "\n",
    "test_set = read_idx('t10k-images-idx3-ubyte.mat')\n",
    "test_set = np.expand_dims(test_set, axis=3)\n",
    "print(test_set.shape)\n",
    "test_label = read_idx('t10k-labels-idx1-ubyte.mat')\n",
    "test_label = np.expand_dims(test_label, axis=1)\n",
    "print(test_label.shape)\n",
    "n_train = train_set.shape[0]\n",
    "n_test = test_set.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
    "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.squeeze(labels)\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0] * 10\n",
    "        if num == 10:\n",
    "            one_hot[0] = 1.0\n",
    "        else:\n",
    "            one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    labels = np.array(one_hot_labels).astype(np.float32)\n",
    "    return labels\n",
    "\n",
    "train_label_one_hot = one_hot(train_label)\n",
    "test_label_one_hot = one_hot(test_label)\n",
    "\n",
    "print(train_label_one_hot.shape)\n",
    "print(test_label_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_CNN:\n",
    "    def __init__(self, wd_factor, learning_rate): #initialize all the variable to be used in the other functions\n",
    "        self.wd_factor = wd_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='input') #to make a 28 times 28 minipatch swipe\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
    "        \n",
    "        # For batch norm and dropout\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        print(self.input)\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        weights = []  # for weight decay\n",
    "        \n",
    "        with tf.variable_scope('layers'):\n",
    "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
    "            \n",
    "            # Downsample\n",
    "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
    "            print(h)\n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.flatten(h)\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                activation=tf.nn.relu, name='dense1')\n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
    "            print(h)\n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                          activation=tf.identity, name='dense2')\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
    "                                                                                  labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay()\n",
    "            \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "    def weight_decay(self):\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer:]\n",
    "            self.train_pointer = 0\n",
    "        return samples_minibatch, labels_minibatch\n",
    "\n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
    "        print('Start Training')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                \n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "                    \n",
    "            saver.save(sess, './model')\n",
    "        return losses\n",
    "                    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer:]\n",
    "            self.test_pointer = 0\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "            \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        self.test_pointer = 0\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "            saver.restore(sess, './model')\n",
    "            while not end_of_epoch:\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
    "        print(\"Average test loss: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"layers/pool1/MaxPool:0\", shape=(?, 3, 3, 64), dtype=float32)\n",
      "Tensor(\"layers/flatten/Reshape:0\", shape=(?, 576), dtype=float32)\n",
      "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dropout1/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/conv1/kernel:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Minibatch loss at step 0: 2.6473653316497803\n",
      "Minibatch loss at step 50: 0.3927866518497467\n",
      "Minibatch loss at step 100: 0.20497100055217743\n",
      "Minibatch loss at step 150: 0.25017276406288147\n",
      "Minibatch loss at step 200: 0.14867547154426575\n",
      "Minibatch loss at step 250: 0.12555837631225586\n",
      "Minibatch loss at step 300: 0.1212480291724205\n",
      "Minibatch loss at step 350: 0.11226015537977219\n",
      "Minibatch loss at step 400: 0.2839846909046173\n",
      "Minibatch loss at step 450: 0.1882876753807068\n",
      "Minibatch loss at step 500: 0.10382742434740067\n",
      "Minibatch loss at step 550: 0.051527027040719986\n",
      "Minibatch loss at step 600: 0.0773383155465126\n",
      "Minibatch loss at step 650: 0.07667142897844315\n",
      "Minibatch loss at step 700: 0.053534023463726044\n",
      "Minibatch loss at step 750: 0.09142166376113892\n",
      "Minibatch loss at step 800: 0.13618482649326324\n",
      "Minibatch loss at step 850: 0.052924830466508865\n",
      "Minibatch loss at step 900: 0.04233202710747719\n",
      "Minibatch loss at step 950: 0.06006184220314026\n",
      "Minibatch loss at step 1000: 0.05710606276988983\n",
      "Minibatch loss at step 1050: 0.046342410147190094\n",
      "Minibatch loss at step 1100: 0.08767792582511902\n",
      "Minibatch loss at step 1150: 0.06715255975723267\n",
      "Minibatch loss at step 1200: 0.0243220292031765\n",
      "Minibatch loss at step 1250: 0.0415230356156826\n",
      "Minibatch loss at step 1300: 0.04002411663532257\n",
      "Minibatch loss at step 1350: 0.05560216307640076\n",
      "Minibatch loss at step 1400: 0.0028190347366034985\n",
      "Minibatch loss at step 1450: 0.04196910560131073\n",
      "Minibatch loss at step 1500: 0.05316166952252388\n",
      "Minibatch loss at step 1550: 0.07556722313165665\n",
      "Minibatch loss at step 1600: 0.04368199035525322\n",
      "Minibatch loss at step 1650: 0.07960215955972672\n",
      "Minibatch loss at step 1700: 0.0177305880934\n",
      "Minibatch loss at step 1750: 0.04055119305849075\n",
      "Minibatch loss at step 1800: 0.11718426644802094\n",
      "Minibatch loss at step 1850: 0.04999854415655136\n",
      "Minibatch loss at step 1900: 0.03460689261555672\n",
      "Minibatch loss at step 1950: 0.03050992824137211\n",
      "Minibatch loss at step 2000: 0.031826771795749664\n",
      "Minibatch loss at step 2050: 0.04608742147684097\n",
      "Minibatch loss at step 2100: 0.016369108110666275\n",
      "Minibatch loss at step 2150: 0.026577768847346306\n",
      "Minibatch loss at step 2200: 0.06132219731807709\n",
      "Minibatch loss at step 2250: 0.04873961582779884\n",
      "Minibatch loss at step 2300: 0.027550429105758667\n",
      "Minibatch loss at step 2350: 0.03388500586152077\n",
      "Minibatch loss at step 2400: 0.08790556341409683\n",
      "Minibatch loss at step 2450: 0.029336651787161827\n",
      "Minibatch loss at step 2500: 0.06254583597183228\n",
      "Minibatch loss at step 2550: 0.019714748486876488\n",
      "Minibatch loss at step 2600: 0.029298219829797745\n",
      "Minibatch loss at step 2650: 0.007763519883155823\n",
      "Minibatch loss at step 2700: 0.04281575232744217\n",
      "Minibatch loss at step 2750: 0.030160430818796158\n",
      "Minibatch loss at step 2800: 0.00425513694062829\n",
      "Minibatch loss at step 2850: 0.04485583305358887\n",
      "Minibatch loss at step 2900: 0.00336843216791749\n",
      "Minibatch loss at step 2950: 0.01108990516513586\n",
      "Minibatch loss at step 3000: 0.05234263837337494\n",
      "Minibatch loss at step 3050: 0.008372988551855087\n",
      "Minibatch loss at step 3100: 0.012513329274952412\n",
      "Minibatch loss at step 3150: 0.012976281344890594\n",
      "Minibatch loss at step 3200: 0.03206947445869446\n",
      "Minibatch loss at step 3250: 0.011756524443626404\n",
      "Minibatch loss at step 3300: 0.006852156016975641\n",
      "Minibatch loss at step 3350: 0.04088333621621132\n",
      "Minibatch loss at step 3400: 0.0015571463154628873\n",
      "Minibatch loss at step 3450: 0.020508823916316032\n",
      "Minibatch loss at step 3500: 0.010813340544700623\n",
      "Minibatch loss at step 3550: 0.0035479168873280287\n",
      "Minibatch loss at step 3600: 0.007445608731359243\n",
      "Minibatch loss at step 3650: 0.05848774313926697\n",
      "Minibatch loss at step 3700: 0.004555406980216503\n",
      "Minibatch loss at step 3750: 0.001193256233818829\n",
      "Minibatch loss at step 3800: 0.008744322694838047\n",
      "Minibatch loss at step 3850: 0.05959085375070572\n",
      "Minibatch loss at step 3900: 0.022611552849411964\n",
      "Minibatch loss at step 3950: 0.004503326490521431\n",
      "Minibatch loss at step 4000: 0.03332704305648804\n",
      "Minibatch loss at step 4050: 0.022713767364621162\n",
      "Minibatch loss at step 4100: 0.00951544288545847\n",
      "Minibatch loss at step 4150: 0.016247272491455078\n",
      "Minibatch loss at step 4200: 0.005082853138446808\n",
      "Minibatch loss at step 4250: 0.011607194319367409\n",
      "Minibatch loss at step 4300: 0.06143232062458992\n",
      "Minibatch loss at step 4350: 0.013456501066684723\n",
      "Minibatch loss at step 4400: 0.003001547884196043\n",
      "Minibatch loss at step 4450: 0.025064025074243546\n",
      "Minibatch loss at step 4500: 0.00622921995818615\n",
      "Minibatch loss at step 4550: 0.03335264325141907\n",
      "Minibatch loss at step 4600: 0.01966085657477379\n",
      "Minibatch loss at step 4650: 0.023594709113240242\n",
      "Minibatch loss at step 4700: 0.013995114713907242\n",
      "Minibatch loss at step 4750: 0.016541458666324615\n",
      "Minibatch loss at step 4800: 0.0023529366590082645\n",
      "Minibatch loss at step 4850: 0.011479786597192287\n",
      "Minibatch loss at step 4900: 0.0372154638171196\n",
      "Minibatch loss at step 4950: 0.004704335238784552\n",
      "Minibatch loss at step 5000: 0.046119287610054016\n",
      "Minibatch loss at step 5050: 0.008545097894966602\n",
      "Minibatch loss at step 5100: 0.0005616716807708144\n",
      "Minibatch loss at step 5150: 0.006843496114015579\n",
      "Minibatch loss at step 5200: 0.013399215415120125\n",
      "Minibatch loss at step 5250: 0.02165810950100422\n",
      "Minibatch loss at step 5300: 0.014513048343360424\n",
      "Minibatch loss at step 5350: 0.004955639131367207\n",
      "Minibatch loss at step 5400: 0.03062579222023487\n",
      "Minibatch loss at step 5450: 0.03637077659368515\n",
      "Minibatch loss at step 5500: 0.0009883162565529346\n",
      "Minibatch loss at step 5550: 0.0010727575281634927\n",
      "Minibatch loss at step 5600: 0.0018251368310302496\n",
      "Minibatch loss at step 5650: 0.007890449836850166\n",
      "Minibatch loss at step 5700: 0.011580357328057289\n",
      "Minibatch loss at step 5750: 0.0046685016714036465\n",
      "Minibatch loss at step 5800: 0.007883681915700436\n",
      "Minibatch loss at step 5850: 0.00413511972874403\n",
      "Minibatch loss at step 5900: 0.023429103195667267\n",
      "Minibatch loss at step 5950: 0.01756102591753006\n",
      "Minibatch loss at step 6000: 0.011535601690411568\n",
      "Minibatch loss at step 6050: 0.009568882174789906\n",
      "Minibatch loss at step 6100: 0.0025185097474604845\n",
      "Minibatch loss at step 6150: 0.014252918772399426\n",
      "Minibatch loss at step 6200: 0.0009740582318045199\n",
      "Minibatch loss at step 6250: 0.005076351575553417\n",
      "Minibatch loss at step 6300: 0.0022483766078948975\n",
      "Minibatch loss at step 6350: 0.009070863015949726\n",
      "Minibatch loss at step 6400: 0.039140485227108\n",
      "Minibatch loss at step 6450: 0.006316666025668383\n",
      "Minibatch loss at step 6500: 0.002575396094471216\n",
      "Minibatch loss at step 6550: 0.014311037957668304\n",
      "Minibatch loss at step 6600: 0.027845343574881554\n",
      "Minibatch loss at step 6650: 0.003520261263474822\n",
      "Minibatch loss at step 6700: 0.006348112132400274\n",
      "Minibatch loss at step 6750: 0.0032694311812520027\n",
      "Minibatch loss at step 6800: 0.006695298012346029\n",
      "Minibatch loss at step 6850: 0.013389714993536472\n",
      "Minibatch loss at step 6900: 0.0191002506762743\n",
      "Minibatch loss at step 6950: 0.0067891934886574745\n",
      "Minibatch loss at step 7000: 0.004678848199546337\n",
      "Minibatch loss at step 7050: 0.008315932005643845\n",
      "Minibatch loss at step 7100: 0.0010837088339030743\n",
      "Minibatch loss at step 7150: 0.0178715568035841\n",
      "Minibatch loss at step 7200: 0.019264880567789078\n",
      "Minibatch loss at step 7250: 0.0173689853399992\n",
      "Minibatch loss at step 7300: 0.00020314505673013628\n",
      "Minibatch loss at step 7350: 0.029961496591567993\n",
      "Minibatch loss at step 7400: 0.01117225643247366\n",
      "Minibatch loss at step 7450: 0.016857115551829338\n",
      "Minibatch loss at step 7500: 0.00019110084394924343\n",
      "Minibatch loss at step 7550: 0.0055900877341628075\n",
      "Minibatch loss at step 7600: 0.0032376833260059357\n",
      "Minibatch loss at step 7650: 0.0005902581033296883\n",
      "Minibatch loss at step 7700: 0.002858109772205353\n",
      "Minibatch loss at step 7750: 0.0023161950521171093\n",
      "Minibatch loss at step 7800: 0.010038990527391434\n",
      "Minibatch loss at step 7850: 0.04201367869973183\n",
      "Minibatch loss at step 7900: 0.005036334507167339\n",
      "Minibatch loss at step 7950: 0.0005528235924430192\n",
      "Minibatch loss at step 8000: 0.004484117031097412\n",
      "Minibatch loss at step 8050: 0.0014421868836507201\n",
      "Minibatch loss at step 8100: 0.0016994749894365668\n",
      "Minibatch loss at step 8150: 0.05835903063416481\n",
      "Minibatch loss at step 8200: 0.01026674173772335\n",
      "Minibatch loss at step 8250: 0.0014913775958120823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 8300: 0.003739788895472884\n",
      "Minibatch loss at step 8350: 0.01212353352457285\n",
      "Minibatch loss at step 8400: 0.014489312656223774\n",
      "Minibatch loss at step 8450: 0.008609862998127937\n",
      "Minibatch loss at step 8500: 0.0016174113843590021\n",
      "Minibatch loss at step 8550: 0.003483514068648219\n",
      "Minibatch loss at step 8600: 0.004136069677770138\n",
      "Minibatch loss at step 8650: 0.011587075889110565\n",
      "Minibatch loss at step 8700: 0.003361356444656849\n",
      "Minibatch loss at step 8750: 0.0079616978764534\n",
      "Minibatch loss at step 8800: 0.00924171693623066\n",
      "Minibatch loss at step 8850: 0.005935979075729847\n",
      "Minibatch loss at step 8900: 0.001545205363072455\n",
      "Minibatch loss at step 8950: 0.0022975292522460222\n",
      "Minibatch loss at step 9000: 0.015901800245046616\n",
      "Minibatch loss at step 9050: 0.0257068183273077\n",
      "Minibatch loss at step 9100: 0.0009391727508045733\n",
      "Minibatch loss at step 9150: 0.004651824943721294\n",
      "Minibatch loss at step 9200: 0.01709110476076603\n",
      "Minibatch loss at step 9250: 0.005801157560199499\n",
      "Minibatch loss at step 9300: 0.0008342170040123165\n",
      "Minibatch loss at step 9350: 0.0075036222115159035\n",
      "Minibatch loss at step 9400: 0.015325287356972694\n",
      "Minibatch loss at step 9450: 0.0004935660981573164\n",
      "Minibatch loss at step 9500: 0.003705513896420598\n",
      "Minibatch loss at step 9550: 0.0017071004258468747\n",
      "Minibatch loss at step 9600: 0.0010948826093226671\n",
      "Minibatch loss at step 9650: 0.017084138467907906\n",
      "Minibatch loss at step 9700: 0.0007145767449401319\n",
      "Minibatch loss at step 9750: 0.0011914176866412163\n",
      "Minibatch loss at step 9800: 0.011470351368188858\n",
      "Minibatch loss at step 9850: 0.004325623624026775\n",
      "Minibatch loss at step 9900: 0.0005328182014636695\n",
      "Minibatch loss at step 9950: 0.02359379082918167\n",
      "Training time: 1015.0110878944397s\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "losses = model.train(train_set, train_label_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: {}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    losses = np.array(losses)\n",
    "    np.save('./train_losses.npy', losses)\n",
    "    print(losses.shape)\n",
    "except NameError:\n",
    "    losses = np.load('./train_losses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = losses[:, 0]\n",
    "train_loss = losses[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, 'b-')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Average test loss: 0.04431871697306633\n"
     ]
    }
   ],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "model.test(test_set, test_label_one_hot, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Test sample digit: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network prediction probabilities:\n",
      "[1.0000000e+00 4.1197924e-21 3.1334962e-18 5.2993878e-22 1.4845170e-20\n",
      " 4.5447880e-22 1.0536494e-18 8.6437165e-17 1.6443058e-15 2.8721703e-17]\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "sample = np.expand_dims(test_set[example], axis=0)\n",
    "label = np.expand_dims(test_label_one_hot[example], axis=0)\n",
    "\n",
    "digit = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "\n",
    "image = np.reshape(sample, (28, 28))\n",
    "\n",
    "print(\"Test sample digit: {}\".format(digit))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Test example\")\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 1.0\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax[1].bar(classes, prediction, width, color='Blue')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Network categorical distribution')\n",
    "ax[1].set_xticks(classes)\n",
    "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "ax[1].set_xlabel('Digit class')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Network prediction probabilities:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time : 1356.0372931957245 s, or  22 min 36.03729319572449 s\n",
      "total parameters involved : 392\n"
     ]
    }
   ],
   "source": [
    "train_time = end_time - start_time\n",
    "print('total training time :', train_time, 's, or ', int(train_time/60), 'min', train_time%60, 's' )\n",
    "count = len(tf.global_variables())\n",
    "print('total parameters involved :', count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
